# CPU メモリ階層

現代のCPUメモリ階層の構造を理解することは、特に行列乗算演算（DGEMM）のようなパフォーマンス重視の処理を最適化するために非常に重要です。以下に、メモリ階層の概要とその特性について説明します。

## メモリ階層の構造

現代のコンピューターアーキテクチャは、速度と容量のバランスを取るために階層構造を採用しています。Ryzen 3970Xを例に、速い順に構成を見ていきます：
詳細は、[WikiChipのZen2のページ](https://en.wikichip.org/wiki/amd/microarchitectures/zen_2)に出ていたものを使いました。


![メモリ階層の図](memory-hierarchy-diagram.svg)

1. **CPU レジスタ**
   - アクセス時間：0 または 1サイクル（約0.27 ns）
   - 容量：ベクトルレジスタ約5 KiB + 通常レジスタ ≒ 合計約6.4 KiB
   - 特徴：最速だが最も小容量
   - 備考：レジスタ間のMOVだとムーブエリミネーションで0サイクルになる

2. **TLB (Translation Lookaside Buffer)**
   - アクセス時間:1〜2サイクル(約0.27〜0.54 ns)
   - 容量:エントリ数128〜512 (全体で約4〜16 KiB相当)
   - 特徴:仮想アドレス→物理アドレス変換をキャッシュし、ページテーブルウォークを削減
   - 備考:L1 TLB（小容量・超高速）とL2 TLB（やや大容量・中速）に分かれる設計も一般的
3. **L1 キャッシュ**
   - アクセス時間：整数操作 4～5サイクル（約1.08～1.35 ns）、浮動小数点操作 7～8サイクル（約1.89～2.16 ns）
   - 容量：L1D 32 KiB（データ用）、L1I 32 KiB（命令用）
   - 特徴：コア専用の高速キャッシュで、命令とデータに分離

4. **L2 キャッシュ**
   - アクセス時間：12サイクル以上（約3.24 ns以上）
   - 容量：512 KiB/コア
   - 特徴：各コアに専用で割り当てられる中速キャッシュ

5. **L3 キャッシュ**
   - アクセス時間：平均39サイクル（約10.54 ns）
   - 容量：16 MiB/CCX（4 MiB×4スライス）
   - 特徴：複数コア間で共有される大容量キャッシュ

6. **メインメモリ (RAM)**
   - アクセス時間：ヒット時約10～15 ns（オープンページ）、ミス時約38～61 ns（別ページ）
   - 容量：数GB～数TB
   - 特徴：大容量だが、キャッシュに比べて遅い

7. **ディスク (SSD/HDD)**
   - アクセス時間：ミリ秒～秒単位
   - 容量：数百GB～数TB
   - 特徴：最大容量だが最も遅い

## 相対的なアクセス時間の比較
CPUレジスタのアクセス時間を1秒と仮定した場合の各メモリ階層の相対的なアクセス時間は以下のようになります：

1. **CPU レジスタ**: 1秒（基準）
2. **L1 キャッシュ**: 約4〜8秒
3. **L2 キャッシュ**: 約12秒以上
4. **L3 キャッシュ**: 約39秒
5. **メインメモリ (RAM)**: 約37〜226秒
6. **ディスク**:
   - **SSD**: 約10時間〜4日
   - **HDD**: 約4日〜43日

この比較から分かるように、メモリ階層間のアクセス時間には桁違いの差があります。CPUレジスタからL3キャッシュまでは比較的小さい差ですが、メインメモリへのアクセスは大幅に遅くなり、さらにディスクへのアクセスになると劇的に時間がかかります。この違いが、キャッシュフレンドリーなアルゴリズム設計の重要性を示しています。

## メモリ階層の重要性

この階層構造が存在する主な理由は、速度と容量のトレードオフです。速いメモリほど製造コストが高く小容量になりますが、遅いメモリは比較的安価で大容量を実現できます。

効率的なアルゴリズム設計（特にDGEMMのような行列演算）では、この階層構造を意識し、データアクセスパターンを最適化することでキャッシュヒット率を高め、全体的なパフォーマンスを向上させることが可能になります。

この階層構造が存在する理由は、速度と容量のトレードオフにあります。速いメモリは高価で小容量、遅いメモリは安価で大容量です。

### TLB（Translation Lookaside Buffer）の重要性

TLB は、仮想アドレスと物理アドレスの対応情報（ページテーブルエントリ）をキャッシュする、CPU 内蔵の超高速かつ小容量のメモリです。TLB があることで、通常なら L4 ページテーブルまで走査する必要がある変換処理を省略し、一度のアクセスで仮想→物理変換を完了できます。  TLB ミスが起こると、ハードウェアまたは OS がページテーブルを参照して再登録しますが、このオーバーヘッドは大規模データ処理や DGEMM のような行列演算では無視できません。そこでパネルパッキング導入がTLB ミスの抑制に効果的です。  メモリ階層全体から見ると、TLB はレジスタとキャッシュの間に位置し、アドレス変換のボトルネックを解消する要の層です。高速なキャッシュヒット率と並列スループットを両立させるには、TLB の効率化が不可欠と言えます。

### 余談：メモリ階層を意識した実践的データ処理

余談になりますが、最近筆者は大量のデータ処理に取り組んでいます。この作業は、ディスクから大量のデータを読み出し、計算の完了状態を確認した後、未完了の場合には非常に小さなインプットファイルのみを抽出するというものです。読み込むデータ量は多く100TB程度で、書き込みファイルの数は総体で数千万程度と大量です。しかし一回に書き込むファイルの大きさは数ギガバイトとごくわずかです。

この処理をHDDで行うと非常に低速です。ファイルををたくさん作るとHDDに負担が大きいのです。従って高速なSSDを使用すると処理速度が数倍から10倍程度に向上します。しかし、処理するデータ量が比較的少ない場合は、RAMに作業用ディスク（RAMディスク）を構築するという選択肢もあります。前述のメモリアクセス時間のスケール表を見れば明らかなように、どんなに高性能なSSDを使用してもRAMディスクの方が圧倒的に高速です。SSDからのデータはさらにPCIeバスを通るので余計なオーバーヘッドが生じます。一方RAMディスクはメモリバスで完結します。

このような「性能の感覚」を持っておくことは、コンピュータリソースを効果的に活用する上で非常に重要です。メモリ階層の特性を理解し、適切なストレージ選択ができることが、効率的なデータ処理の鍵となるのです。
## メモリアクセスの影響

DGEMMのようなデータ集約型の計算では、メモリアクセスが主要なボトルネックとなります。これは「メモリウォール」と呼ばれる問題です。

$`メモリウォール = \frac{計算時間}{メモリアクセス時間} \ll 1`$

大規模な行列乗算では、すべてのデータをL1キャッシュに収めることができないため、キャッシュミスが発生します。

```math
$$ \text{演算量} = O(n^3)、\text{データ量} = O(n^2) $$
```

n×n行列の乗算では、演算量はO(n³)ですが、必要なデータ量はO(n²)です。データ量は少ないとはいえ、毎回メインメモリから行列のデータを読むのは、50～100倍程度遅くします。しかし、各行列要素を複数回再利用できれば計算効率が飛躍的に向上するのがわかると思います。

## プログラムの複雑化

CPUアーキテクチャの重要な特徴の一つは、キャッシュの使用が暗黙的だということです。そして、プログラムからの直接制御がほとんど不可能なことです。

### CPUにおけるキャッシュ制御の限界

CPUでは、キャッシュ階層は基本的にハードウェアによって自動管理され、プログラマには以下のような制約があります：

1. **暗黙的なキャッシュ管理**: CPUはデータの参照パターンに基づいて自動的にキャッシュを管理します
2. **間接的な制御**: プログラマがキャッシュの内容を直接指定する命令はほとんどありません
3. **ヒューリスティックな予測**: キャッシュの置換ポリシーはハードウェアによって決定され、プログラマには不透明です

対照的に、GPUなどの特殊プロセッサでは：

1. **明示的なキャッシュ制御**: データを共有メモリやテクスチャキャッシュに明示的にロードする命令
2. **メモリ階層の直接アクセス**: 異なるメモリ階層（グローバルメモリ、共有メモリなど）を明示的に指定可能
3. **同期機能**: キャッシュの整合性を保つための同期プリミティブ

### CPUでのキャッシュ最適化の限られた手段

CPUプログラマがキャッシュ使用を最適化するための限られた手段としては：

1.  **メモリの再配置**: メモリを一挙に確保しそこにコピーを行うとL1/L2/L3キャッシュにどれかに載せることができます。
2.  **プリフェッチ命令**: 将来必要になるデータを事前にキャッシュに読み込むヒントをCPUに与える
   ```c
   // インテルのプリフェッチ命令の例
   _mm_prefetch((char*)&array[index+16], _MM_HINT_T0);
   ```

3. **非テンポラルストア**: キャッシュをバイパスしてメインメモリに直接書き込む
   ```c
   _mm_stream_si32((int*)&dest[i], data);
   ```

4. **キャッシュラインフラッシュ**: 特定のキャッシュラインを無効化する（通常はシステムレベルの操作）

これらの操作はいずれも「ヒント」に過ぎず、CPUがそれらを尊重するかどうかは保証されません。

### 暗黙的キャッシュによる複雑性の増加

このようなCPUの特性により、高性能アルゴリズムには以下のような複雑さが生じます：

1. **間接的最適化**: メモリアクセスパターンを通じて間接的にキャッシュ動作を制御する必要がある
2. **実験的チューニング**: 異なるアクセスパターンのパフォーマンスを測定し、最適な方法を探る必要がある
3. **プラットフォーム依存**: キャッシュサイズや動作が異なるCPU間で最適化が異なる

このため、高性能なDGEMM実装は、プログラマがCPUの詳細を深く理解し、それに合わせて複雑な間接的最適化を行う必要があり、コードがさらに複雑化します。これは、アルゴリズムの理解しやすさと保守性を犠牲にしてパフォーマンスを向上させるトレードオフの一例です。

## キャッシュミスの影響

キャッシュミスの種類とDGEMMへの影響：

1. **コンパルソリーミス**: 初めてデータにアクセスする際に発生
2. **容量ミス**: キャッシュがデータセット全体を保持できない場合
3. **コンフリクトミス**: 異なるメモリ位置が同じキャッシュラインにマッピングされる場合
4. **TLBミス**: ページテーブル参照に失敗する場合->あまり話題に上らないが今回ではパネルがそれにあたります。

標準的な行列乗算の場合：

```math
$$ C_{ij} = \sum_{k=0}^{n-1} A_{ik} \times B_{kj} $$
```

この計算では、A行列は行方向に、B行列は列方向にアクセスされます。しかし、多くのプログラミング言語では配列は行優先で格納されるため、B行列へのアクセスはキャッシュ非効率的です。
