# CPU メモリ階層

行列乗算演算（DGEMM）のパフォーマンスを理解するためには、現代のCPUメモリ階層の構造を把握することが重要です。この知識は、キャッシュフレンドリーなアルゴリズムの設計に不可欠です。

## メモリ階層の概要

現代のコンピューターアーキテクチャは、次のような階層構造を持っています（速度が速い順）：

1. **CPU レジスタ**: 数ナノ秒のアクセス時間、数KB
2. **L1 キャッシュ**: 約1-3ナノ秒、数十KB（通常データ用とインストラクション用に分かれる）
3. **L2 キャッシュ**: 約3-10ナノ秒、数百KB〜数MB
4. **L3 キャッシュ**: 約10-20ナノ秒、数MB〜数十MB
5. **メインメモリ (RAM)**: 約50-100ナノ秒、数GB〜数TB
6. **ディスク (SSD/HDD)**: ミリ秒〜秒単位、数百GB〜数TB

この階層構造が存在する理由は、速度と容量のトレードオフにあります。速いメモリは高価で小容量、遅いメモリは安価で大容量です。

![メモリ階層の図](memory-hierarchy-diagram.svg)

## 相対的なアクセス時間のスケール

CPUレジスタのアクセス時間を1秒と仮定した場合の各メモリ階層の相対的なアクセス時間は以下のようになります：

1. **CPU レジスタ**: 1秒（基準）
2. **L1 キャッシュ**: 1-3秒
3. **L2 キャッシュ**: 3-10秒
4. **L3 キャッシュ**: 10-20秒
5. **メインメモリ (RAM)**: 1分-1分40秒
6. **ディスク**:
   - **SSD**: 3時間 -1日
   - **HDD**: 11日-115日

この極端な違いが、なぜDGEMMのようなデータ集約型アルゴリズムでキャッシュ最適化が非常に重要なのかを示しています。

### 余談：メモリ階層を意識した実践的データ処理

余談になりますが、最近筆者は大量のデータ処理に取り組んでいます。この作業は、ディスクから大量のデータを読み出し、計算の完了状態を確認した後、未完了の場合には非常に小さなインプットファイルのみを抽出するというものです。読み込むデータ量は多く100TB程度で、書き込みファイルの数は数千万程度と大量です。しかし一回に書き込むファイルの大きさは数ギガバイトとごくわずかです。

この処理をHDDで行うと非常に低速ですが、高速なSSDを使用すると処理速度が数倍に向上します。しかし、処理するデータ量が比較的少ない場合は、RAMに作業用ディスク（RAMディスク）を構築するという選択肢もあります。前述のメモリアクセス時間のスケール表を見れば明らかなように、どんなに高性能なSSDを使用してもRAMディスクの方が圧倒的に高速です。

このような「性能の感覚」を持っておくことは、コンピュータリソースを効果的に活用する上で非常に重要です。メモリ階層の特性を理解し、適切なストレージ選択ができることが、効率的なデータ処理の鍵となるのです。
## メモリアクセスの影響

DGEMMのようなデータ集約型の計算では、メモリアクセスが主要なボトルネックとなります。これは「メモリウォール」と呼ばれる問題です。

$`メモリウォール = \frac{計算時間}{メモリアクセス時間} \ll 1`$

大規模な行列乗算では、すべてのデータをL1キャッシュに収めることができないため、キャッシュミスが発生します。

```math
$$ \text{演算量} = O(n^3)、\text{データ量} = O(n^2) $$
```

n×n行列の乗算では、演算量はO(n³)ですが、必要なデータ量はO(n²)です。データ量は少ないとはいえ、毎回メインメモリから行列のデータを読むのは、50～100倍程度遅くします。しかし、各行列要素を複数回再利用できれば計算効率が飛躍的に向上するのがわかると思います。

## プログラムの複雑化

CPUアーキテクチャの重要な特徴の一つは、キャッシュの使用が暗黙的であり、プログラマからの直接制御がほとんど不可能なことです。

### CPUにおけるキャッシュ制御の限界

CPUでは、キャッシュ階層は基本的にハードウェアによって自動管理され、プログラマには以下のような制約があります：

1. **暗黙的なキャッシュ管理**: CPUはデータの参照パターンに基づいて自動的にキャッシュを管理します
2. **間接的な制御**: プログラマがキャッシュの内容を直接指定する命令はほとんどありません
3. **ヒューリスティックな予測**: キャッシュの置換ポリシーはハードウェアによって決定され、プログラマには不透明です

対照的に、GPUなどの特殊プロセッサでは：

1. **明示的なキャッシュ制御**: データを共有メモリやテクスチャキャッシュに明示的にロードする命令
2. **メモリ階層の直接アクセス**: 異なるメモリ階層（グローバルメモリ、共有メモリなど）を明示的に指定可能
3. **同期機能**: キャッシュの整合性を保つための同期プリミティブ

### CPUでのキャッシュ最適化の限られた手段

CPUプログラマがキャッシュ使用を最適化するための限られた手段としては：

1. **プリフェッチ命令**: 将来必要になるデータを事前にキャッシュに読み込むヒントをCPUに与える
   ```c
   // インテルのプリフェッチ命令の例
   _mm_prefetch((char*)&array[index+16], _MM_HINT_T0);
   ```

2. **非テンポラルストア**: キャッシュをバイパスしてメインメモリに直接書き込む
   ```c
   _mm_stream_si32((int*)&dest[i], data);
   ```

3. **キャッシュラインフラッシュ**: 特定のキャッシュラインを無効化する（通常はシステムレベルの操作）

これらの操作はいずれも「ヒント」に過ぎず、CPUがそれらを尊重するかどうかは保証されません。

### 暗黙的キャッシュによる複雑性の増加

このようなCPUの特性により、高性能アルゴリズムには以下のような複雑さが生じます：

1. **間接的最適化**: メモリアクセスパターンを通じて間接的にキャッシュ動作を制御する必要がある
2. **実験的チューニング**: 異なるアクセスパターンのパフォーマンスを測定し、最適な方法を探る必要がある
3. **プラットフォーム依存**: キャッシュサイズや動作が異なるCPU間で最適化が異なる

このため、高性能なDGEMM実装は、プログラマがCPUの詳細を深く理解し、それに合わせて複雑な間接的最適化を行う必要があり、コードがさらに複雑化します。これは、アルゴリズムの理解しやすさと保守性を犠牲にしてパフォーマンスを向上させるトレードオフの一例です。

## キャッシュミスの影響

キャッシュミスの種類とDGEMMへの影響：

1. **コンパルソリーミス**: 初めてデータにアクセスする際に発生
2. **容量ミス**: キャッシュがデータセット全体を保持できない場合
3. **コンフリクトミス**: 異なるメモリ位置が同じキャッシュラインにマッピングされる場合
4. **TLBミス**: ページテーブル参照に失敗する場合

標準的な行列乗算の場合：

```math
$$ C_{ij} = \sum_{k=0}^{n-1} A_{ik} \times B_{kj} $$
```

この計算では、A行列は行方向に、B行列は列方向にアクセスされます。しかし、多くのプログラミング言語では配列は行優先で格納されるため、B行列へのアクセスはキャッシュ非効率的です。
