# マイクロカーネルの設計

大きいものを小さいものに段階的にブロック行列に分解してゆき、キャッシュ階層をうまくつかいつつ、メモリアクセスを極力避けるのがDGEMMの高速化の重要なところです。プログラミングの観点からゆくと、小さいものから大きいものを作ったほうが見通しがよくなります。ここでは一番内側のループとなる、マイクロカーネルの設計をやってみましょう。

## 1. 概要
最内ループ(マイクロカーネル)では $`C = A\,B`$そして、大きさは$`C\in\mathbb{R}^{m_R\times n_R},\quad A\in\mathbb{R}^{m_R\times k_R},\quad B\in\mathbb{R}^{k_R\times n_R}`$です。 

そして、
行列 $`A`$ のk列だけ取り出した列ベクトル
```math
\begin{bmatrix}
  a_{1k} \\
  a_{2k} \\
  \vdots \\
  a_{m_R\,k}
\end{bmatrix}
```
行列 $`B`$ のk行だけ取り出した行ベクトル 

```math
\begin{bmatrix} b_{k1} & b_{k2} & \dots & b_{k\,n_R} \end{bmatrix} 
```
と表して、
```math
C = \sum_k \begin{bmatrix} a_{1k}\\ a_{2k}\\ \vdots\\ a_{m_R\,k} \end{bmatrix} \! \begin{bmatrix} b_{k1} & b_{k2} & \dots & b_{k\,n_R} \end{bmatrix} 
```

という **rank-1 update** を $`k`$ 回繰り返して行列 $`C`$ を計算します。

### 4x4の場合
具体的な場合を考えてみましょう。4x4の正方行列A, B, CをC=ABと掛け算するとき、rank-1アップデートでは、以下のように計算します。

```math
C = \begin{bmatrix}
C_{11} & C_{12} & C_{13} & C_{14} \\
C_{21} & C_{22} & C_{23} & C_{24} \\
C_{31} & C_{32} & C_{33} & C_{34} \\
C_{41} & C_{42} & C_{43} & C_{44}
\end{bmatrix}
=
\sum_k \begin{bmatrix}
a_{1k}\\
a_{2k}\\
a_{3k}\\
a_{4k}
\end{bmatrix}
\begin{bmatrix}
b_{k1} & b_{k2} & b_{k3} & b_{k4}
\end{bmatrix}
```

ランク1-アップデート第一回目の結果は、

```math
C^{(1)}  = \begin{bmatrix}
C_{11}^{(1)} & C_{12}^{(1)} & C_{13}^{(1)} & C_{14}^{(1)} \\
C_{21}^{(1)} & C_{22}^{(1)} & C_{23}^{(1)} & C_{24}^{(1)} \\
C_{31}^{(1)} & C_{32}^{(1)} & C_{33}^{(1)} & C_{34}^{(1)} \\
C_{41}^{(1)} & C_{42}^{(1)} & C_{43}^{(1)} & C_{44}^{(1)}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}\\
a_{21}\\
a_{31}\\
a_{41}
\end{bmatrix}
\begin{bmatrix}
b_{11} & b_{12} & b_{13} & b_{14}
\end{bmatrix}
```

です。もう少し分解してみると、

ランク1-アップデート第一回め、1回目の演算は以下のようになります。
```math
\begin{bmatrix}
C^{(1)}_{11} \\[4pt]
C^{(1)}_{21} \\[4pt]
C^{(1)}_{31} \\[4pt]
C^{(1)}_{41}
\end{bmatrix}
=
\begin{bmatrix}
a_{11} \\[4pt]
a_{21} \\[4pt]
a_{31} \\[4pt]
a_{41}
\end{bmatrix}
\,b_{11}
```
となります。このとき、CはAVXのレジスタ一本に入ります。$`a_{11} a_{21} a_{31} a_{41}`$もAVX一本のレジスタに入ります。$`b_{11}`$は同じ値を一つのAVX一本のレジスタにコピー(これをブロードキャストとよぶ)して計算は以下のようになります。
```math
\begin{bmatrix}
C^{(1)}_{11} \\[4pt]
C^{(1)}_{21} \\[4pt]
C^{(1)}_{31} \\[4pt]
C^{(1)}_{41}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}\,b_{11} \\[6pt]
a_{21}\,b_{11} \\[6pt]
a_{31}\,b_{11} \\[6pt]
a_{41}\,b_{11}
\end{bmatrix}
```
このようにCの一列目に足しこんでゆきます。２回目は、$`b_{12}`$について行います。
```math
\begin{bmatrix}
C^{(1)}_{12} \\[4pt]
C^{(1)}_{22} \\[4pt]
C^{(1)}_{32} \\[4pt]
C^{(1)}_{42}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}\,b_{12} \\[6pt]
a_{21}\,b_{12} \\[6pt]
a_{31}\,b_{12} \\[6pt]
a_{41}\,b_{12}
\end{bmatrix}
```

### まとめると、
一回のrank 1アップデートは、k回スカラーとベクトル掛けてベクトルに足しこむに分解できます。


## 2. レジスタ制約
* rank-1アップデートでは計算途上では$`C`$に書き戻さず、マイクロカーネルを抜けるときに書き戻します。従って$`C`$をレジスタに持っておくことが重要となります。
* Zen 2 アーキテクチャでは 256-bit YMM レジスタが **16 本/コア** 利用可能です。
* 一般的には **半数のレジスタを $`C`$ の保持** に割り当て、残りを *$`A`$ と $`B`$ のプリフェッチ* およびループ制御変数に使用します。

## ロード隠蔽条件
演算１回分の実行時間内に **次のデータをL2からレジスタへ転送** する必要があります。L1は後に示すように演算器が全力で計算しているときのデータ消費量とつりあうデータ供給ができるため、ボトルネックになりません。

```math
$$ n_r \;\ge\; \frac{R_\text{comp}}{2\,R_\text{load}}\tag{★} $$
```

* $`R_\text{comp}`$ … 1コアあたりの倍精度浮動小数点演算性能（FLOP/cycle）
* $`R_\text{load}`$ … L2→レジスタへのロード帯域（double/cycle）
* 分母の "2" は、1回のrank-1 updateで **A,B から約2要素** のロードが必要なためです

### Zen 2 プロセッサの特性
* **計算性能** : 1クロックで16FLOP計算(2 × 256-bit FMA/clk → $`R_\text{comp}=16\;\text{FLOP/cycle}`$)
* **メモリ帯域** : L2→L1 32 B/clk = 4 double/clk → $`R_\text{load}=4\;\text{double/cycle}`$

これより
$`n_r \;\ge\; \frac{16}{2\times4}=2`$ 

つまり、**列幅が2以上** であれば、理論上はロード遅延を完全に隠蔽できます。


### なぜL1からレジスタを考慮する必要がないか？
演算器が全力(16 FLOP/cycle)で走っているとき、L1データキャッシュのロードポートも全力(8 double/cycle)で走ればちょうど計算が回るので、L1 は「速いけれど小さいキャッシュ」として十分役目を果たすからです。
もう少し詳しく言うと  
- Ryzen3970Xだと、1クロックで16FLOP計算できます(AVX2 + FMA)。 外積型カーネルでA から 4 double（列ベクトル）B から 1 double をブロードキャスト（実ハードは 4 double ロードして 4 倍書き換え）を読み込み，その組で 8 FLOP を生み出します。2 基ぶん同時に動かすと 16 FLOP に対し 8 double の新データが必要になります。L1 のロード帯域 8 double/サイクル がちょうどこの需要を満たすため、1コアが全力で浮動小数点を行っていることとつりあいます。
- マイクロカーネルは k 方向 に沿ってA(:,p) と B(p,:) を サイクルごとに新しく読みます。ところが L1データキャッシュは 32 KiB しかなく、$m_R \times K$ や $K \times n_R$ のパネル全体は収まりません。したがって L2 が実質的なデータ供給でのボトルネックとなります。

## サイズ候補と評価

| 候補 $`m_R\times n_R`$ | レジスタ使用量 ($`\overline{C}`$) | (★)条件の充足度 | 実用上の特徴 |
|----------------------|---------------|------------|------------|
| 4 × 4                | 4 YMM (25%)   | ◎          | 実装が容易で移植性に優れています |
| 6 × 6                | 9 YMM (56%)   | ◎          | 計算密度が高く、TLB/帯域がボトルネックになりにくいです |
| 4 × 12                | 9 YMM (56%)   | ◎         | プリフェッチ用のレジスタ残量はぎりぎりです |
| 6 × 8                | 12 YMM (75%)  | ◎          | BLISライブラリが採用。プリフェッチ用のレジスタ残量はぎりぎりです |
| 8 × 8                | 16 YMM (100%) | ○          | レジスタ使用率が最大。ロード先行命令の工夫が必要です |

**推奨アプローチ**: まずは **4 × 4** で実装し、性能プロファイルを確認した上で **6 × 6** へ拡張するのが安全です。

## 5. 教育用 4 × 4 AVX2 カーネル（抜粋）

```cpp
#include <immintrin.h>

inline void micro_kernel_4x4(
    const double* A, const double* B, double* C,
    std::size_t ldc, std::size_t k)
{
    __m256d c0 = _mm256_loadu_pd(C + 0*ldc);
    __m256d c1 = _mm256_loadu_pd(C + 1*ldc);
    __m256d c2 = _mm256_loadu_pd(C + 2*ldc);
    __m256d c3 = _mm256_loadu_pd(C + 3*ldc);

    for (std::size_t p = 0; p < k; ++p) {
        __m256d a   = _mm256_loadu_pd(A + 4*p);
        __m256d bp0 = _mm256_broadcast_sd(B + p*4 + 0);
        __m256d bp1 = _mm256_broadcast_sd(B + p*4 + 1);
        __m256d bp2 = _mm256_broadcast_sd(B + p*4 + 2);
        __m256d bp3 = _mm256_broadcast_sd(B + p*4 + 3);

        c0 = _mm256_fmadd_pd(a, bp0, c0);
        c1 = _mm256_fmadd_pd(a, bp1, c1);
        c2 = _mm256_fmadd_pd(a, bp2, c2);
        c3 = _mm256_fmadd_pd(a, bp3, c3);
    }

    _mm256_storeu_pd(C + 0*ldc, c0);
    _mm256_storeu_pd(C + 1*ldc, c1);
    _mm256_storeu_pd(C + 2*ldc, c2);
    _mm256_storeu_pd(C + 3*ldc, c3);
}
```

## 6. まとめ
* **レジスタ半分ルール** と **(★) ロード隠蔽条件** がマイクロカーネルサイズ選定の基本指針です。
* Zen 2 アーキテクチャでは **$`n_r\ge2`$** を満たすことで帯域律速を回避できます。
* 実装では **4 × 4** から始め、必要に応じて **6 × 6** または **6 × 8** へ拡張し、レジスタ使用率とロードポート飽和のバランスを調整するとよいでしょう。
