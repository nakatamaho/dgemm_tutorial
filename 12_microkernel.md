# マイクロカーネルの設計

大きいものを小さいものに段階的にブロック行列に分解してゆき、キャッシュ階層をうまくつかいつつ、メモリアクセスを極力避けるのがDGEMMの高速化の重要なところです。ただプログラミングの観点からゆくと、小さいものから大きいものを作ったほうが見通しがよくなります。ここでは一番内側のループとなる、マイクロカーネルの設計をやってみましょう。

## 行列-行列積はrank-one updateで作るのが定石
最内ループ(マイクロカーネル)では $`C = A\,B`$そして、大きさは$`C\in\mathbb{R}^{m_R\times n_R},\quad A\in\mathbb{R}^{m_R\times k_R},\quad B\in\mathbb{R}^{k_R\times n_R}`$です。 

そして、
行列 $`A`$ のk列だけ取り出した列ベクトル
```math
\begin{bmatrix}
  a_{1k} \\
  a_{2k} \\
  \vdots \\
  a_{m_R\,k}
\end{bmatrix}
```
行列 $`B`$ のk行だけ取り出した行ベクトル 

```math
\begin{bmatrix} b_{k1} & b_{k2} & \dots & b_{k\,n_R} \end{bmatrix} 
```
と表して、
```math
C = \sum_k \begin{bmatrix} a_{1k}\\ a_{2k}\\ \vdots\\ a_{m_R\,k} \end{bmatrix} \! \begin{bmatrix} b_{k1} & b_{k2} & \dots & b_{k\,n_R} \end{bmatrix} 
```

という **rank-1 update** を $`k`$ 回繰り返して行列 $`C`$ を計算します。

### 4x4の場合
具体的な場合を考えてみましょう。4x4の正方行列A, B, CをC=ABと掛け算するとき、rank-1アップデートでは、以下のように計算します。

```math
C = \begin{bmatrix}
C_{11} & C_{12} & C_{13} & C_{14} \\
C_{21} & C_{22} & C_{23} & C_{24} \\
C_{31} & C_{32} & C_{33} & C_{34} \\
C_{41} & C_{42} & C_{43} & C_{44}
\end{bmatrix}
=
\sum_k \begin{bmatrix}
a_{1k}\\
a_{2k}\\
a_{3k}\\
a_{4k}
\end{bmatrix}
\begin{bmatrix}
b_{k1} & b_{k2} & b_{k3} & b_{k4}
\end{bmatrix}
```

ランク1-アップデート第一回目の結果は、

```math
C^{(1)}  = \begin{bmatrix}
C_{11}^{(1)} & C_{12}^{(1)} & C_{13}^{(1)} & C_{14}^{(1)} \\
C_{21}^{(1)} & C_{22}^{(1)} & C_{23}^{(1)} & C_{24}^{(1)} \\
C_{31}^{(1)} & C_{32}^{(1)} & C_{33}^{(1)} & C_{34}^{(1)} \\
C_{41}^{(1)} & C_{42}^{(1)} & C_{43}^{(1)} & C_{44}^{(1)}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}\\
a_{21}\\
a_{31}\\
a_{41}
\end{bmatrix}
\begin{bmatrix}
b_{11} & b_{12} & b_{13} & b_{14}
\end{bmatrix}
```

です。もう少し分解してみると、

ランク1-アップデート第一回め、1回目の演算は以下のようになります。
```math
\begin{bmatrix}
C^{(1)}_{11} \\[4pt]
C^{(1)}_{21} \\[4pt]
C^{(1)}_{31} \\[4pt]
C^{(1)}_{41}
\end{bmatrix}
=
\begin{bmatrix}
a_{11} \\[4pt]
a_{21} \\[4pt]
a_{31} \\[4pt]
a_{41}
\end{bmatrix}
\,b_{11}
```
となります。実際の計算は以下のようになります。
```math
\begin{bmatrix}
C^{(1)}_{11} \\[4pt]
C^{(1)}_{21} \\[4pt]
C^{(1)}_{31} \\[4pt]
C^{(1)}_{41}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}\,b_{11} \\[6pt]
a_{21}\,b_{11} \\[6pt]
a_{31}\,b_{11} \\[6pt]
a_{41}\,b_{11}
\end{bmatrix}
```
このようにCの一列目に足しこんでゆきます。２回目は、$`b_{12}`$について行います。
```math
\begin{bmatrix}
C^{(1)}_{12} \\[4pt]
C^{(1)}_{22} \\[4pt]
C^{(1)}_{32} \\[4pt]
C^{(1)}_{42}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}\,b_{12} \\[6pt]
a_{21}\,b_{12} \\[6pt]
a_{31}\,b_{12} \\[6pt]
a_{41}\,b_{12}
\end{bmatrix}
```

これをあと2回続けると、rank-1アップデートの第一回目が完了します。
```math
C^{(1)}  = \begin{bmatrix}
C_{11}^{(1)} & C_{12}^{(1)} & C_{13}^{(1)} & C_{14}^{(1)} \\
C_{21}^{(1)} & C_{22}^{(1)} & C_{23}^{(1)} & C_{24}^{(1)} \\
C_{31}^{(1)} & C_{32}^{(1)} & C_{33}^{(1)} & C_{34}^{(1)} \\
C_{41}^{(1)} & C_{42}^{(1)} & C_{43}^{(1)} & C_{44}^{(1)}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}\\
a_{21}\\
a_{31}\\
a_{41}
\end{bmatrix}
\begin{bmatrix}
b_{11} & b_{12} & b_{13} & b_{14}
\end{bmatrix}
```
これを4回続けてやれば、rank-1アップデートによる$`C=AB`$が完成します。

### まとめると、
一回のrank 1アップデートは、4回スカラーとベクトル掛けてベクトルに足しこむに分解できます。

### 理論的考察：なぜrank1アップデートは有利か？

$n_R \times m_R$サイズのブロック行列で1回のrank-1更新（外積計算）を考えると：

1. **ロード量**：
   - A行列から$`n_R`$要素（1列分）
   - B行列から$`m_R`$要素（1行分）
   - 合計：$`n_R + m_R`$要素

2. **演算量**：
   - C行列の$`n_R \times m_R`$個の要素を更新
   - 各要素に1回のFMA操作（2 FLOP）を実行
   - 合計：$`2 \times n_R \times m_R`$ FLOP

ロード隠蔽条件は「演算時間 ≥ ロード時間」より：

```math
\frac{2 \times n_R \times m_R}{R_{\text{comp}}} \geq \frac{n_R + m_R}{R_{\text{load}}}
```

特に正方行列ブロック（$`n_R = m_R`$）の場合、これは以下のように単純化されます：

```math
n_R \geq \frac{R_{\text{comp}}}{R_{\text{load}}} \cdots (\text{★})
```

ここで：
* $`R_{\text{comp}}`$ = 1コアあたりの倍精度浮動小数点演算性能（FLOP/cycle）
* $`R_{\text{load}}`$ = L2→レジスタへのロード帯域（double/cycle）

データの使いまわしが効率的。L2->L1->CPUへのメモリ転送を完全に隠蔽できます。

### ナイーブアプローチとの比較

行列乗算 $C = A \times B$ で $A(n \times k)$, $B(k \times m)$ の場合：

- **ロード量**: $n \times k + k \times m$ 要素
- **演算量**: $n \times m \times (2k-1)$ FLOP
- **問題点**: 頻繁なメモリアクセスによるキャッシュミス

#### メモリ転送隠蔽の理論的考察

ナイーブな実装でのメモリ転送隠蔽条件を考えます。計算時間がメモリロード時間以上である必要があります：

```math
\frac{n \times m \times (2k-1)}{R_{\text{comp}}} \geq \frac{n \times k + k \times m}{R_{\text{load}}}
```

ここで：
- $R_{\text{comp}}$ = 計算速度（FLOP/サイクル）
- $R_{\text{load}}$ = ロード帯域（要素/サイクル）

#### 正方行列の場合

特に $n = m = k$ の正方行列の場合、条件は以下のように単純化されます：

```math
\frac{n^2 \times (2n-1)}{R_{\text{comp}}} \geq \frac{2n^2}{R_{\text{load}}}
```

これを整理すると：

```math
\frac{2n-1}{2} \geq \frac{R_{\text{comp}}}{R_{\text{load}}}
```

$n$ が十分大きい場合、近似的に：

```math
n \geq \frac{R_{\text{comp}}}{R_{\text{load}}}
```
### rank one とナイーブな計算との比較

1. **ロード効率**:
   - ナイーブアプローチ: 全行列要素 ($`n \times k + k \times m`$) をロード
   - ランク1アプローチ: 各ステップで一部 ($`n_R + m_R`$) のみロード

2. **キャッシュ活用**:
   - ナイーブアプローチ: 同じデータへの繰り返しアクセスでキャッシュミスが頻発
   - ランク1アプローチ: ブロック単位の処理でキャッシュ効率が向上

3. **実際の条件達成**:
   - ナイーブアプローチ: メモリアクセスパターンが非局所的で実際には隠蔽条件を満たしにくい
   - ランク1アプローチ: ブロックサイズを調整することで条件を満たしやすい

### Ryzen 3970X (Zen 2)プロセッサでの適用

Zen 2プロセッサの仕様：
* **計算性能**: 1クロックあたり16 FLOP（2基の256-bit FMA/clock）→ $`R_{\text{comp}} = 16 \text{ FLOP/cycle}`$
* **メモリ帯域**: L2→L1で32 バイト/clock = 4 double/clock → $`R_{\text{load}} = 4 \text{ double/cycle}`$

これを上記の式に代入すると：

```math
n_R \geq \frac{16}{4} = 4
```

したがって、**ブロック計算の列幅（$`n_R`$）が4以上**であれば、理論上はロード遅延を完全に隠蔽できることになります。

### 4×4行列の場合（$`n_R = m_R = 4`$）

**演算回数**：
* 4×4=16要素の更新 × 2 FLOP/要素 = 32 FLOP
* 演算時間：$`32 \text{ FLOP} \div 16 \text{ FLOP/cycle} = 2 \text{ cycles}`$

**メモリ読み出し回数**：
* A行列から4要素、B行列から4要素 = 合計8要素
* ロード時間：$`8 \text{ double} \div 4 \text{ double/cycle} = 2 \text{ cycles}`$

**ちょうど隠蔽条件が成立**

### 結論

Zen 2プロセッサでDGEMMを最適化する場合：

1. 理論式 $`n_R \geq \frac{R_{\text{comp}}}{R_{\text{load}}}`$ から、$`n_R \geq 4`$ という条件が導かれる
2. 計算すると$`n_R = m_R = 4`$以上のブロックでロード隠蔽が達成できることが確認できる
3. Zen 2プロセッサでDGEMMを実装する際は、**最低でも4×4以上のブロックサイズ**を使用することで、メモリロードの遅延を隠蔽し、理論演算性能に近い実行効率を達成できるはずです

### なぜL1からレジスタを考慮する必要がないか？
演算器が全力(16 FLOP/cycle)で走っているとき、L1データキャッシュのロードポートも全力(8 double/cycle読み、4 double/cycle書き)で走ればちょうど計算が回るので、L1 は「小さいけれど必要十分に高速なキャッシュ」として十分役目を果たすからです。これはどんなCPUでも成り立つように設計されているはずです。
もう少し詳しく言うと 
- Ryzen 3970X のL1からCPUへのロード帯域は 64 バイト/サイクル、ストア帯域は 32 バイト/サイクルです。つまり1サイクルで8個のbinary64を読め、4個のbinary64を書き込めます。
- Ryzen3970Xだと、1クロックで16FLOP計算できます(AVX2 + FMA)。 外積型カーネルでA から 4 double（列ベクトル）B から 1 double をブロードキャスト（１double ロードして 4 個コピーをつくる）を読み込み，その組で 8 FLOP を生み出します。2 基ぶん同時に動かすと 16 FLOP に対し 8 double の新データが必要になります。L1 のロード帯域 8 double/サイクル がちょうどこの需要を満たすため、1コアが全力で浮動小数点を行っていることとつりあいます。
- マイクロカーネルは k 方向 に沿ってA(:,p) と B(p,:) を サイクルごとに新しく読みます。ところが L1データキャッシュは 32 KiB しかなく、$`m_R \times K`$ や $`K \times n_R`$ のパネル全体は収まりません。したがって L2 が実質的なデータ供給でのボトルネックとなります。
- 逆に考えます。Ryzen 3970X は binary64 で 1クロック最大 16FLOP 計算可能です。何かの計算をすることでこの 16FLOP を計算するとし、二つの数の FMA を 8回行うことになります。つまり乗算と加算という二回の演算を 8個の binary64 について行えば 8×2=16FLOP 演算となり、演算器を埋めることができます。そして結果の書き込みも 4個の binary64 を L1キャッシュに可能です。
- L1キャッシュが完全に動いたとして、演算器にも完全にデータを供給したり、回収できない設計だと、そもそも演算器が無駄になります。無駄が発生するうような CPU の設計は絶対にしないのです。

## サイズ候補と評価

| 候補 $`m_R\times n_R`$ | レジスタ使用量 ($`\overline{C}`$) | (★)条件の充足度 | 実用上の特徴 |
|----------------------|---------------|------------|------------|
| 4 × 4                | 4 YMM (25%)   | ◎          | 実装が容易で移植性に優れています |
| 6 × 6                | 9 YMM (56%)   | ◎          | 計算密度が高く、TLB/帯域がボトルネックになりにくいです |
| 4 × 12                | 12 YMM (75%)   | ◎         | 今回最速。プリフェッチ用のレジスタ残量はぎりぎりです |
| 6 × 8                | 12 YMM (75%)  | ◎          | BLISライブラリが採用。プリフェッチ用のレジスタ残量はぎりぎりです |
| 8 × 8                | 16 YMM (100%) | ○          | レジスタ使用率が最大。ロード先行命令の工夫が必要です |

## 6. まとめ
* **レジスタ半分ルール** と **(★) ロード隠蔽条件** がマイクロカーネルサイズ選定の基本指針です。
* Zen 2 アーキテクチャでは **$`n_r\ge2`$** を満たすことで帯域律速を回避できます。
* 実装では **4 × 4** から始め、様々なカーネルを実装し比較します。
