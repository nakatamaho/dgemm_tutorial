# 19. まとめ: DGEMM チュートリアルの総括

本チュートリアルでは、以下のステップでDGEMMの高速化手法を解説しました。初心者向けの内容: 行列-行列積のBLASの紹介、FLOPS、およびCPUのFLOPSや詳しいアーキテクチャの調べ方、C/C++での行列の書き方(手で一次元配列に開くこと)、メモリーレイアウト、デバッグノウハウ、メモリーの速度の階層構造、行列のブロッキングの数理などを説明したあと、

中級者向け

1. **ランク-1アップデート法**  
   行列積を外積（ランク-1行列）の和として実装し、1要素ずつのドット積読み込みを大幅に削減。  
   - メモリアクセス削減率は $`\frac{2m_R n_R}{m_R + n_R}`$

2. **マイクロカーネルの設計**  
   ブロックサイズ $`m_R \times n_R`$ をレジスタに保持し、rank-1アップデートを繰り返す実装。  
   - レジスタレベルでのデータ再利用を最大化し、L1/L2キャッシュへの依存を最小化

3. **NoAVX 4×4マイクロカーネルの実装**  
   AVX2を用いないスカラー版4×4カーネルで性能評価。  
   - レジスタを用いたCブロックの累積とロード／ストアの抑制により、単純なトリプルループ実装を超える性能を実現

4. **パネル化**  
   L2/L3キャッシュを意識してAパネル（MR×KC）、Bパネル（KC×NC）を生成し、多段ブロッキングを適用。  
   - コピー時の連続アクセスとストライド最適化でTLBミス・キャッシュミスを削減

5. **階層的ブロック化技術**  
   NC, MC, KCレベルの3重ループとMR, NRのマイクロカーネルでキャッシュ階層に対応。  
   - 各レベルでのデータ再利用パターンとループ入れ子順序の最適化を示し

6. **AVX2 4×4マイクロカーネル**  
   256ビットSIMD命令を用い、A列ロード＋B要素のブロードキャスト＋FMAによる高速累積実装。  
   - `__restrict`指定やalignedロードで命令レベル並列性とメモリバンド幅を最大活用

7. **カーネルサイズ比較**  
   Threadripper 3970X上で4×12が最高性能を発揮し、4×8→8×4→8×8の順で性能が低下。  
   - レジスタ数、キャッシュライン、メモリアクセスパターンとの整合性に起因

8. **OpenMPを用いたマルチコア並列化**  
   NMKループ（N→M→K）を `#pragma omp parallel for collapse(2)` で並列化し、32C×64T環境で1.3 TFLOPS超を達成。  
   - スレッドローカルパネルバッファによる false-sharing 回避と負荷分散戦略を提示

## その他
 * データの流れは目に見えないため、暗中模索の感覚があり、最適化にはアーキテクチャの詳しい知識とそれに応じた最適化戦略が非常に重要。
   - Gotoらの論文、及びその解説も。
   - 年々CPUなどは複雑化してきているため、単純にある戦略の延長上では高速化されず、一進一退というのが必要だった。
 * ChatGPTやClaude.ai、NotebookLMなどAIは非常に役に立った。
   - 大量の試行錯誤が必要のため大量のコードを書く必要があった。自動で書けたため心がおれなかった。特にAVX2のマイクロカーネル作成が大変楽になった。
   - (明らかな)間違いがあるときなど自分の理解度が試された。理解するためにはちょうどよかった。
   - 速いコードを出せだけでは高速化されず、されたとしても次の段階に行けない。理解は重要、たとえば、政治におけるリーダーはある程度頭がよくなくてはならない
   - 論文の解説をしてもらうと、理解が速くなる。論文解説のpodcastはありがたかった。
   - DeepResearchのように歴史的な背景もわかると、理解もしやすくなる。

## 総括
- シングルスレッドでは **N→K→M**、マルチスレッドでは **N→M→K** が最適。  
- ランク-1アップデート＋マイクロカーネル＋階層的ブロック化＋SIMD＋並列化の組み合わせで、理論性能に近い実装が可能。  
- 今後はプリフェッチ、非対称コア最適化、さらに上位のブロッキング戦略など拡張したいなァ...
