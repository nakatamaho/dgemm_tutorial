# 19. まとめ

## 1. DGEMMの基礎とインターフェース  
- 行列乗算の定義と計算量 $`O(n^3)`$ の重要性。数値線形代数、機械学習、量子化学、シミュレーションでコア演算となる 
- DGEMM演算式  
  $`C \gets \alpha\,\mathrm{op}(A)\,\mathrm{op}(B) + \beta\,C`$  
  と `TRANSA`/`TRANSB`、および先導次元 (LDA/LDB/LDC) の指定方法 

## 2. 理論ピーク性能（FLOPS）の計算  
- **FLOP**（1回の浮動小数点演算）と**FLOPS**（秒間FLOP数）の定義と、理論ピーク性能の意義 
- Ryzen Threadripper 3970X のスペック：32C/64T、3.7 GHz～4.5 GHz、AVX2 (256 bit)、L1/L2/L3 キャッシュ容量などの提示と調べ方。

## 3. プレDGEMM: ナイーブ実装  
- C言語での3重ループによる基本的行列積プログラム。動的配列確保、表示関数付き、非常に低速

## 4. 行列のメモリレイアウト  
- メモリ階層（キャッシュライン）と空間的局所性の重要性  
- C/C++での行列の取り扱い: Row‐Major vs Column‐Major
- C/C++での行列の取り扱い: 1次元配列への展開インデックス計算を陽に行うのがベスト

## 5. 先導次元の概念  
- Leading Dimension (LD) とは、列優先メモリ上で「次の列の先頭に飛ぶステップ幅」を指すパラメータ 
- BLAS DGEMM 呼び出し時に `lda`, `ldb`, `ldc` として指定  

## 6. 最も簡単なDGEMM実装 (NN版)  
- BLAS準拠のDGEMMを実装。

## 7. OpenBLASとの比較  
- OpenBLASのビルド (`make target=ZEN2` / `apt-get install libopenblas-dev`)、Makefile例  
- 自作シンプル実装 vs OpenBLAS のベンチマーク結果比較 100倍以上違う

## 8. DGEMMデバッグテクニック  
- Octave/Matlab形式出力で結果検証、小整数乱数＋番兵値でブロック化バグ検出、4×4テスト、LDに余裕を持たせることなどを活用 

## 9. メモリ階層の理解  
- レジスタ→L1→L2→L3→RAM→ディスクの階層構造とアクセス時間差、メモリウォール問題  
- キャッシュフレンドリーなアルゴリズム設計の重要性 

## 10. ブロッキングの数理  
- 行列 $`A\!(m{\times}k)`$, $`B\!(k{\times}n)`$ を $`b{\times}b`$ ブロックに分割し、各ブロック単位で積を計算できる、計算する、理論的根拠  
- ブロックサイズとキャッシュ局所性の関係

## 11. ランク-1アップデート法  
- 行列積を外積（ランク-1行列）の和として再構成し、データの再利用およびメモリアクセスを大幅削減

## 12. マイクロカーネル設計  
- $`m_R{\times}n_R`$ ブロックをレジスタに保持し、ランク-1アップデートを繰り返す実装でデータ再利用最大化 

## 13. NoAVX 4×4マイクロカーネル  
- AVXを使わないスカラー版4×4カーネル。レジスタ内累積とロード/ストア抑制により性能向上
  
## 14. パネル化のプログラミング
- L2/L3キャッシュを意識し、Aパネル（$`M_R{\times}K_C`$）、Bパネル（$`K_C{\times}N_C`$）を一度コピーして再利用  
  
## 15. 階層的ブロック化のプログラミング  

- 三段階: L3キャッシュのブロック化、L2/L3パネルのブロック化、L1とレジスタのブロック化
- パネル化：キャッシュに行列のデータを乗せる良いやり方、しかもロードにかかる時間も隠蔽可能
- パネル化：転置も取りやすい
- パネル化：TLB最適化でキャッシュにも優しく、キャッシュミスが減る。
  
## 16. AVX2 4×4マイクロカーネル  
- 256bit SIMD命令でA列ロード＋Bのブロードキャスト＋FMAによる高速累積  
- `__restrict` や alignedロードでパイプライン／メモリ帯域活用

## 17. カーネルサイズ比較  
- さまざまなサイズでマイクロカーネルを実装。
- Ryzen 3970X上で 4×12 が最高性能、次いで 4×8→8×4→8×8
- レジスタ数、キャッシュライン、アクセスパターンとの整合性が要因
- ループ順序も変えてみる
  
## 18. OpenMP並列化  
- N→M→K ループを `#pragma omp parallel for collapse(2)` で並列化し、32C×64T環境で1.3 TFLOPS超  
- スレッドローカルバッファによる false-sharing 回避と負荷分散戦略

## その他
 * 最適化はRyzen3970Xのように32コアもある場合は4コア、8コアより難しい。とるべき戦略も違うと考えられる
 * データの流れは目に見えないため、暗中模索の感覚があり、最適化にはアーキテクチャの詳しい知識とそれに応じた最適化戦略が非常に重要。
   - Gotoらの論文、及びその解説は非常に重要
   - 年々CPUなどは複雑化してきているため、単純にある戦略の延長上では高速化されず（ループ順序はシングルスレッドとマルチスレッドで違う）、一進一退というのが必要だった（多段ブロッキングは意外と難しいのでまずマイクロカーネル、次にパネル化、最後にキャッシュブロック）。
 * ChatGPTやClaude.ai、NotebookLMなどAIは非常に役に立った。
   - 大量の試行錯誤が必要のため大量のコードを書く必要があった。自動で書けたため心がおれなかった。特にAVX2のマイクロカーネル作成が大変楽になった。
   - (明らかな)間違いがあるときなど自分の理解度が試された。理解するためにはちょうどよかった。
   - 速いコードを出せだけでは高速化されず、されたとしても次の段階に行けない。理解は重要、たとえば、政治におけるリーダーはある程度頭がよくなくてはならない
   - 論文の解説をしてもらうと理解が速くなる。論文解説のpodcastはありがたかった。
   - DeepResearchを行い、アルゴリズム発展の歴史的な背景もわかると、理解しやすくなる（昔になるほど単純なので分かりやすい）。

## 総括
- シングルスレッドでは **N→K→M**、マルチスレッドでは **N→M→K** が最適。  (性能モデルも違う)
- ランク-1アップデート＋マイクロカーネル＋階層的ブロック化＋SIMD＋並列化の組み合わせで、理論性能に近い実装が可能。  
- 今後はNN以外、行列の端数対応、プリフェッチ、非対称コア最適化、さらに上位のブロッキング戦略など...
