# 19. まとめ: DGEMM チュートリアルの総括

本チュートリアルでは、以下のステップでDGEMMの高速化手法を解説しました。

1. **ランク-1アップデート法**  
   行列積を外積（ランク-1行列）の和として実装し、1要素ずつのドット積読み込みを大幅に削減。  
   - メモリアクセス削減率は $`\frac{2m_R n_R}{m_R + n_R}`$

2. **マイクロカーネルの設計**  
   ブロックサイズ $`m_R \times n_R`$ をレジスタに保持し、rank-1アップデートを繰り返す実装。  
   - レジスタレベルでのデータ再利用を最大化し、L1/L2キャッシュへの依存を最小化

3. **NoAVX 4×4マイクロカーネルの実装**  
   AVX2を用いないスカラー版4×4カーネルで性能評価。  
   - レジスタを用いたCブロックの累積とロード／ストアの抑制により、単純なトリプルループ実装を超える性能を実現

4. **パネル化**  
   L2/L3キャッシュを意識してAパネル（MR×KC）、Bパネル（KC×NC）を生成し、多段ブロッキングを適用。  
   - コピー時の連続アクセスとストライド最適化でTLBミス・キャッシュミスを削減

5. **階層的ブロック化技術**  
   NC, MC, KCレベルの3重ループとMR, NRのマイクロカーネルでキャッシュ階層に対応。  
   - 各レベルでのデータ再利用パターンとループ入れ子順序の最適化を示し

6. **AVX2 4×4マイクロカーネル**  
   256ビットSIMD命令を用い、A列ロード＋B要素のブロードキャスト＋FMAによる高速累積実装。  
   - `__restrict`指定やalignedロードで命令レベル並列性とメモリバンド幅を最大活用

7. **カーネルサイズ比較**  
   Threadripper 3970X上で4×12が最高性能を発揮し、4×8→8×4→8×8の順で性能が低下。  
   - レジスタ数、キャッシュライン、メモリアクセスパターンとの整合性に起因

8. **OpenMPを用いたマルチコア並列化**  
   NMKループ（N→M→K）を `#pragma omp parallel for collapse(2)` で並列化し、32C×64T環境で1.3 TFLOPS超を達成。  
   - スレッドローカルパネルバッファによる false-sharing 回避と負荷分散戦略を提示

## その他
 - データの流れは目に見えないため、暗中模索の感覚がある。
 - 最適化にはアーキテクチャの詳しい知識とそれに応じた最適化戦略が非常に重要。
 - Gotoらの論文、及びその解説も大変重要。
 - ChatGPTやClaude.aiは非常に役に立った。μカーネル作成が大変楽になった。
 - ChatGPTやClaude.aiは非常に役に立った。ただ、明らかな間違いがあるときなど自分の理解度が試される(理解するためにはちょうどよかった)
 - 速いコードを出せだけでは高速化されず、されたとしても次の段階に行けない。理解は重要(政治におけるリーダーは頭がよくなくてはならない)

## 総括
- シングルスレッドでは **N→K→M**、マルチスレッドでは **N→M→K** が最適。  
- ランク-1アップデート＋マイクロカーネル＋階層的ブロック化＋SIMD＋並列化の組み合わせで、理論性能に近い実装が可能。  
- 今後はプリフェッチ、非対称コア最適化、さらに上位のブロッキング戦略など拡張したいなァ...
