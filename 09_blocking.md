# 09 ブロッキングの数理 (Blocking)

> **狙い** — 本節では、行列積 *C ← A B* を「ブロック（タイル）」単位で計算できる**数学的な根拠**を示し、さらにキャッシュ階層と結び付けてブロックサイズを選ぶ指針を概観します。実装テクニックは次章で詳述し、ここではあくまで理論的背景にフォーカスします。

---

## 1  なぜブロッキングが必要か

ハイエンド CPU では、浮動小数点演算性能 (FLOP/s) とメモリ帯域 (B/s) の比—いわゆる **Roofline モデル**の *算術集約度*—が年々開いています。配列要素を *1 回* しか再利用できないアルゴリズムはメモリ帯域に律速され、理論演算ピークのごく一部しか発揮できません。

行列積 `DGEMM` は $O(N^3)$ の演算量に対し、要素の総転送量は $O(N^2)$ です。**各要素を $O(N)$ 回再利用できる**ため、うまくメモリ局所性を確保すれば帯域律速を回避できます。これを実現する最も直接的な手段が *ブロッキング* です。

---

## 2  行列をブロックで表す

まず、$A\in\mathbb{R}^{m\times k}$ と $B\in\mathbb{R}^{k\times n}$ を**一様サイズ $b$** の正方ブロックに分割するとします（端部は切り詰めるか不完全ブロックになります）。整数

$$
  p=\lceil m/b \rceil,\; q=\lceil k/b \rceil,\; r=\lceil n/b \rceil
$$

を用いると，例えば $A$ は

$$
A = \begin{bmatrix}
  A_{00} & \cdots & A_{0,q-1} \\
  \vdots & \ddots & \vdots \\
  A_{p-1,0} & \cdots & A_{p-1,q-1}
\end{bmatrix},\qquad
A_{ij}\in\mathbb{R}^{b_i\times b_j},
$$

と書けます（$b_i,b_j\le b$）。$B$ も同様にブロック化できます。

---

## 3  ブロック行列積の定理

> **定理 1 (ブロック行列積)** — 上記のブロック分割に対して，行列積 $C = A B$ を同じブロック形に並べると
>
> $$
>   C_{ij} = \sum_{\ell=0}^{q-1} A_{i\ell}\,B_{\ell j}\qquad(0\le i<p,\;0\le j<r)
> $$
>
> が成り立つ。ここで $C_{ij}\in\mathbb{R}^{b_i\times b_j}$ は $C$ の $(i,j)$ ブロックである。

### 証明

各 $C_{ij}$ の $(\alpha,\beta)$ 成分 ($0\le\alpha<b_i$, $0\le\beta<b_j$) を展開すると

$$
  (C_{ij})_{\alpha\beta} = \sum_{x=0}^{k-1} A_{i\,\alpha,\,x}\;B_{x,\,j\,\beta}
$$

ですが、添字 $x$ はブロック範囲 $b$ ごとに区切れます。$x=\ell b+\gamma$ と置けば $\ell$ がブロック番号 ($0\le\ell<q$)、$\gamma$ がブロック内オフセット ($0\le\gamma<b_{\ell}$) です。

$$
  (C_{ij})_{\alpha\beta}
  = \sum_{\ell=0}^{q-1}\;\sum_{\gamma=0}^{b_{\ell}-1}
     A_{i\ell,\,\alpha\gamma}\;B_{\ell j,\,\gamma\beta}
  = \bigl(A_{i\ell} B_{\ell j}\bigr)_{\alpha\beta},
$$

よって主張の式が示されました。\qed

### 帰結

* 乗算は *ブロック単位で完全に独立* に行える。
* $\ell$ に対する総和はスカラーの場合と同一形式で、アルゴリズム的には「$k$ ループ」をブロック幅 $b$ ごとに粗く刻んだだけ。

---

## 4  メモリ階層とブロックサイズの指針

各ブロック乗算 `C_{ij} += A_{iℓ} B_{ℓj}` は大きさ $b\times b$ の行列積で、**ワーキングセット** (ロード＋ストア) は

$$
  W = 2b^2 + b^2 = 3b^2 \text{ elements}.
$$

倍精度 (8 bytes) なら `$24b^2` bytes` です。これを特定キャッシュに収めたい場合、容量 $C$ に対して

$$
  24b^2\;\le\;C
$$

を満たす最大 $b$ を選ぶのが第一近似となります。例えば、

| キャッシュ階層 | 容量 $C$ | 最大 $b\;\approx\;\sqrt{C/24}$ |
|-----------------|----------|---------------------------------|
| L1 (32 kB) | 32 × $2^{10}$ = 32768 B | $\approx 37$ |
| L2 (512 kB) | 524288 B | $\approx 148$ |
| L3 (32 MB)  | 33,554,432 B | $\approx 1183$ |

実装ではさらに **プリフェッチ単位**, **TLB エントリ数**, **SIMD カーネル幅** といった制約を加味し、しばしば $b$ を 48, 64, 96 … とパディング込みで調整します。

---

## 5  数値安定性について一言

ブロッキングは演算の **集合的順序** を変えません (あくまで $k$ ループの粒度を荒くしただけ) ので、

* 理論上の結果は厳密に一致。
* 丸め誤差は「加算順序」が変わる限りにおいてのみ従来の三重ループと差異がある。

実務上は **BLAS ⇢ LAPACK ⇢ ScaLAPACK** と標準化された実装で十分検証されています。

---

## 6  まとめ

1. ブロッキングは行列をブロック行列とみなす単純な再構成により**厳密な数学的同値**を保証できる。
2. キャッシュ効率の向上により、算術集約度を高めメモリ帯域律速を回避する。
3. ブロックサイズはキャッシュ容量の平方根に比例して決定されるのが第一近似。

次章では、これらの理論を踏まえて **マルチレベルのブロック分割 (L1/L2/L3 → マイクロカーネル)** と SIMD 化を組み合わせた実装戦略を解説します。

