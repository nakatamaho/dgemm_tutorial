# 09 ブロッキングの数理 (Blocking)

> **狙い** — 本節では、行列積 *C ← A B* を「ブロック(タイル)」単位で計算できる**数学的な根拠**を示し、さらにキャッシュ階層と結び付けてブロックサイズを選ぶ指針を概観します。実装テクニックは次章で詳述し、ここではあくまで理論的背景にフォーカスします。

---

## 1 なぜブロッキングが必要か

ハイエンド CPU では、浮動小数点演算性能 (FLOP/s) とメモリ帯域 (B/s) の比—いわゆる **Roofline モデル**の *算術集約度*—が年々開いています。配列要素を *1 回* しか再利用できないアルゴリズムはメモリ帯域に律速され、理論演算ピークのごく一部しか発揮できません。

行列積 `DGEMM` は \$`O(N^3)`\$ の演算量に対し、要素の総転送量は \$`O(N^2)`\$ です。**各要素を \$**``**\$ 回再利用できる**ため、うまくメモリ局所性を確保すれば帯域律速を回避できます。これを実現する最も直接的な手段が *ブロッキング* です。

---

## 2 行列をブロックで表す

まず、\$`A\in\mathbb{R}^{m\times k}`\$ と \$`B\in\mathbb{R}^{k\times n}`\$ を**一様サイズ \$**``**\$** の正方ブロックに分割するとします(端部は切り詰めるか不完全ブロックになります)。整数

```math
$$
  p=\lceil m/b \rceil,\; q=\lceil k/b \rceil,\; r=\lceil n/b \rceil
$$
```

を用いると、例えば行列 \$`A`\$ は以下のようにブロック行列として表せます:

```math
$$
A = \begin{bmatrix}
  A_{00} & \cdots & A_{0,q-1} \\
  \vdots & \ddots & \vdots \\
  A_{p-1,0} & \cdots & A_{p-1,q-1}
\end{bmatrix},\qquad
A_{ij}\in\mathbb{R}^{b_i\times b_j},
$$
```

続いて、対応する \$`B`\$ とその積 \$`AB`\$ も同様にブロック行列で表すと、図示的には次のようになります。





ここで \$`b_i,b_j\le b`\$ です。行列 \$`B`\$ も同様にブロック化できます。

---

## 3 ブロック行列積の定理

> **定理 1 (ブロック行列積)** — ブロック分割に対して,行列積 \$`C = A B`\$ を同じブロック形に並べると
>
> ```math
> $$
>   C_{ij} = \sum_{\ell=0}^{q-1} A_{i\ell}\,B_{\ell j}\qquad(0\le i<p,\;0\le j<r)
> $$
> ```
>
> が成り立つ。ここで \$`C_{ij}\in\mathbb{R}^{b_i\times b_j}`\$ は \$`C`\$ の \$(i,j)\$ ブロックです。

### 証明

各 \$`C_{ij}`\$ の \$(\alpha,\beta)\$ 成分 (\$`0\le\alpha<b_i`\$, `$0\le\beta<b_j`\$) を展開すると

```math
$$
  (C_{ij})_{\alpha\beta} = \sum_{x=0}^{k-1} A_{i\,\alpha,\,x}\;B_{x,\,j\,\beta}
$$
```

しかし添字 \$`x`\$ をブロック単位 \$`b`\$ ごとに分解し、\$`x=\ell b+\gamma`\$ と置くと

```math
$$
  (C_{ij})_{\alpha\beta}
  = \sum_{\ell=0}^{q-1} \sum_{\gamma=0}^{b_{\ell}-1}
     A_{i\ell,\alpha\gamma}\;B_{\ell j,\gamma\beta}
  = \bigl(A_{i\ell} B_{\ell j}\bigr)_{\alpha\beta}.
$$
```

よって定理が示されました。\qed

### 帰結

- 乗算はブロック単位で独立に行える。
- 従来の三重ループの \$`k`\$ ループをブロック幅ごとに粗く刻んだだけで、計算量は変わりません。

---

## 4 メモリ階層とブロックサイズの指針 (Ryzen 3970X)

**Ryzen Threadripper 3970X** の “1 コア当たり” キャッシュ容量をもとに、ワーキングセット

```math
$$
  W = 2N^2 \times 8  \quad [\mathrm{bytes}]
$$
```

(入力行列 2 枚のロード + 出力行列 1 枚のストア、倍精度 8 bytes)を特定キャッシュに収める行列サイズ \$`N_{\max}`\$ を以下から導出します。

| キャッシュ階層            | 容量 \$`C`\$    | \$`N_{\max} = \lfloor \sqrt{C/16} \rfloor`\$ |
| ------------------ | ------------- | -------------------------------------------- |
| L1 Data (32 KB/コア) | 32,768 B      | \$`\approx45`\$                              |
| L2 (512 KB/コア)     | 524,288 B     | \$`\approx181`\$                             |
| L3 (128 MB 共有)     | 134,217,728 B | \$`\approx2896`\$                            |

> **メモ**
>
> - マイクロカーネル (L1) 向けには SIMD 幅やレジスタ数の都合で \$`N=32~64`\$ が一般的です。
> - L1 に Instruction と Data 合計 64 KB を仮定すると \$`N\approx64`\$ になりますが、実使用できるのは Data 側のみです。

---

## 5 数値安定性について一言

ブロッキングは計算の順序を組み替えるのみで、結果の理論的同等性は保たれます。

```math
$$
  \text{丸め誤差の違いは加算順序の差に起因するのみ}
$$
```

標準的な BLAS 実装 (LAPACK, ScaLAPACK) で十分検証されています。

---

## 6 まとめ

1. ブロッキングは行列をブロック行列に見立てる数学的再構成で厳密同等。
2. キャッシュ効率を高めることで算術集約度を改善し、メモリ帯域律速を回避。
3. ブロックサイズはキャッシュ容量の平方根に比例する第一近似。L1: \$`32~64`\$, L2: \$`~181`\$, L3: \$`~2896`\$。

次章ではこれらを踏まえ、マルチレベルブロック分割 (L1/L2/L3 → マイクロ/メソ/マクロカーネル) と SIMD 化の実装戦略を解説します。

