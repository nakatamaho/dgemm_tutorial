# 09 ブロッキングの数理 (Blocking)

> **狙い** — 本節では、行列積 *C ← A B* を「ブロック（タイル）」単位で計算できる**数学的な根拠**を示し、さらにキャッシュ階層と結び付けてブロックサイズを選ぶ指針を概観します。実装テクニックは次章で詳述し、ここではあくまで理論的背景にフォーカスします。

---

## 1 なぜブロッキングが必要か

ハイエンド CPU では、浮動小数点演算性能 (FLOP/s) とメモリ帯域 (B/s) の比—いわゆる **Roofline モデル**の *算術集約度*—が年々開いています。配列要素を *1 回* しか再利用できないアルゴリズムはメモリ帯域に律速され、理論演算ピークのごく一部しか発揮できません。

行列積 `DGEMM` は $`O(N^3)`$ の演算量に対し、要素の総転送量は $`O(N^2)`$ です。**各要素を $`O(N)`$ 回再利用できる**ため、うまくメモリ局所性を確保すれば帯域律速を回避できます。これを実現する最も直接的な手段が *ブロッキング* です。

---

## 2 行列をブロックで表す

まず、$`A\in\mathbb{R}^{m\times k}`$ と $`B\in\mathbb{R}^{k\times n}`$ を**一様サイズ $`b`$** の正方ブロックに分割するとします（端部は切り詰めるか不完全ブロックになります）。整数

```math
$$
  p=\lceil m/b \rceil,\; q=\lceil k/b \rceil,\; r=\lceil n/b \rceil
$$
```

を用いると，例えば $`A`$ は

```math
$$
A = \begin{bmatrix}
  A_{00} & \cdots & A_{0,q-1} \\
  \vdots & \ddots & \vdots \\
  A_{p-1,0} & \cdots & A_{p-1,q-1}
\end{bmatrix},\qquad
A_{ij}\in\mathbb{R}^{b_i\times b_j},
$$
```

と書けます（$`b_i,b_j\le b`$）。$`B`$ も同様にブロック化できます。

---

## 3 ブロック行列積の定理

> **定理 1 (ブロック行列積)** — 上記のブロック分割に対して，行列積 $`C = A B`$ を同じブロック形に並べると
>
> ```math
> $$
>   C_{ij} = \sum_{\ell=0}^{q-1} A_{i\ell}\,B_{\ell j}\qquad(0\le i<p,\;0\le j<r)
> $$
> ```

> が成り立つ。ここで $`C_{ij}\in\mathbb{R}^{b_i\times b_j}`$ は $`C`$ の $(i,j)$ ブロックである。

### 証明

各 $`C_{ij}`$ の $(`\alpha`,`\beta`)$ 成分 ($`0\le\alpha<b_i`$, `$0\le\beta<b_j`$) を展開すると

```math
$$
  (C_{ij})_{\alpha\beta} = \sum_{x=0}^{k-1} A_{i\,\alpha,\,x}\;B_{x,\,j\,\beta}
$$
```

ですが、添字 $`x`$ はブロック範囲 $`b`$ ごとに区切れます。$`x=\ell b+\gamma`$ と置けば $`\ell`$ がブロック番号 (`$0\le\ell<q`$)、$`\gamma`$ がブロック内オフセット (`$0\le\gamma<b_{\ell}`$) です。

```math
$$
  (C_{ij})_{\alpha\beta}
  = \sum_{\ell=0}^{q-1}\;\sum_{\gamma=0}^{b_{\ell}-1}
     A_{i\ell,\,\alpha\gamma}\;B_{\ell j,\,\gamma\beta}
  = \bigl(A_{i\ell} B_{\ell j}\bigr)_{\alpha\beta},
$$
```

よって主張の式が示されました。\qed

### 帰結

* 乗算は *ブロック単位で完全に独立* に行える。
* $`\ell`$ に対する総和は三重ループの $`k`$ ループをブロック幅 $`b`$ ごとに粗く刻んだだけで、アルゴリズム的に同値。

---

## 4 メモリ階層とブロックサイズの指針 (Ryzen 3970X)

以下では **Ryzen Threadripper 3970X** の “**1 コア当たり**” のキャッシュ容量 — DGEMM を並列化しても各スレッドは基本的に自前の L1/L2 を用いるため— をもとに、ワーキングセット

```math
$$
  W = 2N^2\times 8\;[\mathrm{bytes}]
$$
```

（行列 2 枚をロードし 1 枚を書き戻す、倍精度 8 bytes）を特定キャッシュに収めるときの行列サイズ $`N_{\max}`$ を導出します。

| キャッシュ階層                   | 容量 $`C`$              | $`N_{\max}=\left\lfloor\sqrt{C/16}\right\rfloor`$ |
|---------------------------------|-------------------------|-----------------------------------------------:|
| **L1 Data** (32 KB/コア)        | 32,768 B                | $`\approx\mathbf{45}`$                         |
| **L2** (512 KB/コア)            | 524,288 B               | $`\approx\mathbf{181}`$                        |
| **L3** (128 MB 共有)            | 134,217,728 B           | $`\approx\mathbf{2,896}`$                      |

> **メモ**
> - マイクロカーネル (L1 対応) のブロック幅は、SIMD 幅やレジスタ使用量を加味して $`N\approx32\!−\!64`$ が選ばれることが多く、理論上限の 45 と齟齬はありません。
> - 「Instruction + Data の合計 64 KB」を L1 容量とみなす場合は $`N_{\max}\approx64`$ になりますが、データ専有部は概ね Data 32 KB です。
> - L2/L3 の共有振る舞いは複雑ですが、単スレッド解析では上記の “1 コア L2 / 全体 L3” 見積もりが実測に近い指標となります。

---

## 5 数値安定性について一言

ブロッキングは演算の **集合的順序** を変えず、単にループ粒度を粗くするだけです。

- 理論上の結果は完全に一致。
- 丸め誤差は加算順序の違いに起因し、三重ループ版とわずかな差異を生じる場合あり。

実装上は **BLAS ⇢ LAPACK ⇢ ScaLAPACK** の標準ライブラリが十分検証されているため安心です。

---

## 6 まとめ

1. ブロッキングは行列をブロック行列とみなす再構成により **厳密な数学的同値** を保証。
2. キャッシュ効率を高めることで算術集約度を向上させ、メモリ帯域律速を回避。
3. ブロックサイズはキャッシュ容量の平方根に比例して決定されるのが第一近似。L1 用マイクロカーネルは $`32\!−\!64`$、L2 用メソカーネルは $`\sim180`$、L3 用マクロカーネルは $`\sim2,900`$ を目安に。

次章ではこれら理論を踏まえ、**マルチレベルブロック分割 (L1/L2/L3 → マイクロカーネル)** と SIMD 化を組み合わせた実装戦略を解説します。

